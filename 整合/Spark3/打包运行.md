# 运行jar

```bash
ps -ef | grep java

nohup java -jar  xxx.jar 2>&1 > /dev/null &
nohup java -classpath  xxx.jar 2>&1 >  xxx.xxx.classname /dev/null &

```

# Flink on Yarn


[Flink 的三种运行模式](https://niyanchun.com/flink-quick-learning-deployment-mode.html)
[Flink on Yarn两种模式启动参数及在Yarn上的恢复](https://cloud.tencent.com/developer/article/1586186)

[官方参考1](https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/deployment/resource-providers/yarn/)
[官方参考2](https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/deployment/overview/#deployment-modes)

## session 模式

> 第一种模式分为两步：
- yarn-session.sh(开辟资源)
- flink run（提交任务）

```bash
# 开辟资源
yarn-session.sh -n 2 -jm 1024 -tm 1024 -d -s 2

# 参数说明
-n 2 # 表示指定两个容器 
-jm 1024 # 表示jobmanager 1024M内存 
-tm # 1024表示taskmanager 1024M内存 
-d --detached  # 任务后台运行 
-s  # 指定每一个taskmanager分配多少个slots(处理进程)。建议设置为每个机器的CPU核数。一般情况下，vcore的数量等于处理的slot（-s）的数量
-nm,--name # YARN上为一个自定义的应用设置一个名字
-q,--query # 显示yarn中可用的资源 (内存, cpu核数)
-qu,--queue <arg> # 指定YARN队列.
-z,--zookeeperNamespace <arg> # 针对HA模式在zookeeper上创建NameSpace
```
```bash
# 提交任务
./flink run ../examples/batch/WordCount.jar -input hdfs://192.168.83.129:9000/LICENSE -output hdfs://192.168.83.129:9000/wordcount-result.txt
```

## per-job 模式

> 其实也分为两个部分，依然是开辟资源和提交任务，但是在Job模式下，这两步都合成一个命令了

```bash
./flink run -m yarn-cluster -yn 2 -yjm 1024 -ytm 1024 ../examples/batch/WordCount.jar

# 参数
-c,--class <classname> # 如果没有在jar包中指定入口类 则需要在这里通过这个参数指定 
-m,--jobmanager <host:port> # 指定需要连接的jobmanager(主节点)地址 使用这个参数可以指定一个不同于配置文件中的jobmanager 
-p,--parallelism <parallelism> # 指定程序的并行度。可以覆盖配置文件中的默认值
-yjm  # jobmanager内存大小
-ytm  # taskmanager内存大小
-yn # taskmanager个数
-ys    # 一个taskmanager的slot个数
-ynm,--yarnname # 指定任务名称
```

## application 模式

# 部署

> 问题解决

```bash
# parent 打包插件排除的包，可能导致上线运行找不到jar，上线打包要加上

# flink-conf.yaml, 避免POM中的jar 和 flink自带的 冲突
classloader.resolve-order: parent-first
classloader.check-leaked-classloader: false
```

> 部署命令

```bash
# kafka source
nohup java -jar /opt/work/datalake/kafkasource-1.0-SNAPSHOT.jar 2>&1 > /dev/null &
# 查看运行情况
ps -ef | grep kafkasource*
kafka-console-consumer --bootstrap-server hadoop01:9092  --topic ods_ncddzt

# 建表+action
spark-submit --class top.chendaye666.create.CompactSmallFile \
        --master yarn \
        --name rewrite-smalle-file \
        --jars /opt/work/iceberg-spark3-runtime-0.12.0.jar \
        --deploy-mode cluster \
        --driver-memory 1g \
        --executor-memory 1g \
        --executor-cores 2 \
        /opt/work/sparkicebergddl-1.0-SNAPSHOT.jar

# Per-Job Mode    -yjm,--yarnjobManagerMemory <arg>  (MB)/  -ytm,--yarntaskManagerMemory <arg> (MB)
/opt/flink-1.12.5/bin/flink run  -t yarn-per-job  --detached  /opt/work/datalake/ods-1.0-SNAPSHOT.jar
/opt/flink-1.12.5/bin/flink run -m yarn-cluster -ynm ods -yqu root.iceberg  -yjm 1024 -ytm 1024  -ys 2 -d /opt/work/datalake/ods-1.0-SNAPSHOT.jar
/opt/flink-1.12.5/bin/flink run -m yarn-cluster -ynm ods -c top.chendaye666.v2.KafkaToSparkIceberg  -yjm 1024 -ytm 1024 -d /opt/work/datalake/ods-1.0-SNAPSHOT.jar

/opt/flink-1.12.5/bin/flink list -t yarn-per-job -Dyarn.application.id=application_XXXX_YY
/opt/flink-1.12.5/bin/flink cancel -t yarn-per-job -Dyarn.application.id=application_XXXX_YY <jobId>

# Application Mode
/opt/flink-1.12.5/bin/flink run-application -t yarn-application  /opt/work/datalake/ods-1.0-SNAPSHOT.jar
/opt/flink-1.12.5/bin/flink list -t yarn-application -Dyarn.application.id=application_XXXX_YY
/opt/flink-1.12.5/bin/flink cancel -t yarn-application -Dyarn.application.id=application_XXXX_YY <jobId>


# yarn-per-job
/opt/flink-1.12.5/bin/flink run  -t yarn-per-job -h
/opt/flink-1.12.5/bin/flink run -t yarn-per-job -ynm ods -yqu root.iceberg  -yjm 1024 -ytm 1024  -ys 2 -d /opt/work/datalake/ods-1.0-SNAPSHOT.jar

hdfs dfs -rm -r -skipTrash /warehouse/iceberg
```


## yarn 常用命令

```bash
# 类似linux里的top命令，查看正在运行的程序资源使用情况
yarn top

# 查看指定queue使用情况
yarn queue -status root.users.xxxx

# 查看app状态
yarn application -list -appStates 【ALL,NEW,NEW_SAVING,SUBMITTED,ACCEPTED,RUNNING,FINISHED,FAILED,KILLED】

yarn application -list -appTypes[SUBMITTED, ACCEPTED, RUNNING]

# 移动app到对应的队列
yarn application -movetoqueue application_1528080031923_0067 -queue root.users.xxx

# kill掉app
yarn application -kill application_1528080031923_0067

# 查看app状态
yarn application -status application_1528080031923_0067

# 查看app尝试信息
yarn applicationattempt -list application_1528080031923_0064

# 打印类路径 
yarn classpath --glob

# 打印正在执行任务的容器信息
yarn container -list appattempt_1528080031923_0068_000001

# 打印当前容器信息
yarn container -status container_1528080031923_0068_01_000002

# 提交任务到yarn
yarn jar [mainClass] args...

# 查看app运行日志
yarn logs -applicationId application_1528080031923_0064

# 查看所有节点信息
yarn node -all -list

# 查看守护进程日志级别
yarn daemonlog -getlevel n0:8088 rg.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl

# RMStateStore的格式化. 如果过去的应用程序不再需要，则清理RMStateStore
yarn resourcemanager [-format-state-store]



# Usage: yarn rmadmin
yarn rmadmin
-refreshQueues  # 重载队列的ACL，状态和调度器特定的属性，ResourceManager将重载mapred-queues配置文件

-refreshNodes # 动态刷新dfs.hosts和dfs.hosts.exclude配置，无需重启NameNode。

dfs.hosts #：列出了允许连入NameNode的datanode清单（IP或者机器名）

dfs.hosts.exclude #：列出了禁止连入NameNode的datanode清单（IP或者机器名）

# 重新读取hosts和exclude文件，更新允许连到Namenode的或那些需要退出或入编的Datanode的集合。

-refreshUserToGroupsMappings # 刷新用户到组的映射。

-refreshSuperUserGroupsConfiguration # 刷新用户组的配置

-refreshAdminAcls # 刷新ResourceManager的ACL管理

-refreshServiceAclResourceManager #  重载服务级别的授权文件。

-getGroups [username] # 获取指定用户所属的组。

-transitionToActive [–forceactive] [–forcemanual] 尝试将目标服务转为 Active 状态。如果使用了–forceactive选项，不需要核对非Active节点。如果采用了自动故障转移，这个命令不能使用。虽然你可以重写–forcemanual选项，你需要谨慎。

-transitionToStandby [–forcemanual] 将服务转为 Standby 状态. 如果采用了自动故障转移，这个命令不能使用。虽然你可以重写–forcemanual选项，你需要谨慎。

-failover [–forceactive] 启动从serviceId1 到 serviceId2的故障转移。如果使用了-forceactive选项，即使服务没有准备，也会尝试故障转移到目标服务。如果采用了自动故障转移，这个命令不能使用。

-getServiceState 返回服务的状态。（注：ResourceManager不是HA的时候，时不能运行该命令的）

-checkHealth 请求服务器执行健康检查，如果检查失败，RMAdmin将用一个非零标示退出。（注：ResourceManager不是HA的时候，时不能运行该命令的）

-help [cmd]显示指定命令的帮助，如果没有指定，则显示命令的帮助。

```

[CDH yarn参数设置](https://blog.csdn.net/peidezhi/article/details/102729889)